{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61245e36",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4de74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datetime import date\n",
    "from production_training import ProductionTraining\n",
    "import joblib\n",
    "import pickle\n",
    "import json\n",
    "from training_and_evluation import TrainingAndEvaluation\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "from warnings import simplefilter\n",
    "import inspect\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "tae = TrainingAndEvaluation()\n",
    "pt = ProductionTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff5ac6",
   "metadata": {},
   "source": [
    "### 1) Read configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a02cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting configs to class object for easy referral\n",
      "\n",
      "X(model_params=X(learning_rate=0.1, max_features='sqrt', subsample=0.8, random_state=10, model__loss='exponential', model__max_depth=10, model__max_features='auto', model__min_samples_leaf=20, model__min_samples_split=40, model__n_estimators=400), model_path='./production/trained_models/model_2021-04-23.pkl', grid_search=X(last_model_path='./production/grid_search_models/gread_search_2021-04-24.pkl', grid_params=X(n_estimators=[400, 500], max_depth=[12, 14], min_samples_split=[40, 30], min_samples_leaf=[20, 10], max_features=['sqrt'], loss=['exponential', 'deviance']), fixed_params=X(learning_rate=0.1, max_features='sqrt', subsample=0.8, random_state=10)), sanity=X(sanity_check_path='./production/sanity_check/sampels.txt'))\n"
     ]
    }
   ],
   "source": [
    "config_path = './production/configurations/production_configuration.txt'\n",
    "configs = pt.read_json_to_class(config_path)\n",
    "print(f\"Converting configs to class object for easy referral\\n\\n{configs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ca3db",
   "metadata": {},
   "source": [
    "### 2) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3143fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fetures which gave the best results\n",
    "lasso_features = ['has_burglar_alarm',\n",
    "                 'state',\n",
    "                 'previous_policies',\n",
    "                 'card_type',\n",
    "                 'portable_electronics',\n",
    "                 'square_ft',\n",
    "                 'product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c09fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'train_resampled_previous_policies'\n",
    "b = 'train_resampled_k_means_shuffled'\n",
    "c = 'df_resampled'\n",
    "\n",
    "df_not_encoded = pd.read_csv(f'./data/{a}.csv', index_col=[0])\n",
    "df_not_encoded_raw = pd.read_csv(f'./data/df_before_encoding.csv', index_col=[0])\n",
    "\n",
    "df_not_encoded = df_not_encoded[[i for i in df_not_encoded.columns if i not in ['id','user_id','postal_code']]]\n",
    "df_not_encoded_raw = df_not_encoded_raw[[i for i in df_not_encoded_raw.columns if i not in ['id','user_id','postal_code']]]\n",
    "\n",
    "_ , X_test, _ , y_test  = tae.train_test_split(df = df_not_encoded_raw, labeled_col_name = 'label', test_size = 0.15,random_state=20)\n",
    "\n",
    "y_train = df_not_encoded.label\n",
    "X_train = df_not_encoded.drop(columns = 'label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91b850",
   "metadata": {},
   "source": [
    "### 3) Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02b1dd",
   "metadata": {},
   "source": [
    "###### 3.1) Parmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5901144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map columns to types : Categorical, Numeric, Boolean\n",
    "cols = df_not_encoded_raw[lasso_features].columns\n",
    "categorical_cols = [col for col in cols if df_not_encoded_raw[col].dtype == 'object']\n",
    "numerical_cols = [col for col in cols if ((df_not_encoded_raw[col].dtype == 'int64') or (df_not_encoded_raw[col].dtype == 'float64'))]\n",
    "bool_cols = [col for col in cols if df_not_encoded_raw[col].dtype == 'bool' if 'label' != col]\n",
    "\n",
    "\n",
    "# Grid search params\n",
    "gs_params = dict(configs.grid_search.grid_params.__dict__)\n",
    "gs_params = {f'model__{k}':v for k,v in gs_params.items()}\n",
    "\n",
    "# Fixed params \n",
    "fixed_params = dict(configs.grid_search.fixed_params.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4f3fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool_cols\n",
      "\n",
      " ['has_burglar_alarm', 'portable_electronics']\n",
      "\n",
      "\n",
      "categorical_cols\n",
      "\n",
      " ['state', 'card_type', 'product']\n",
      "\n",
      "\n",
      "numerical_cols\n",
      "\n",
      " ['previous_policies', 'square_ft']\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12397 entries, -9.16005e+18_2.49201e+18 to -9.03879e+18_-6.86341e+18\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   state                    12397 non-null  object \n",
      " 1   product                  12397 non-null  object \n",
      " 2   square_ft                12397 non-null  float64\n",
      " 3   has_fire_alarm           12397 non-null  bool   \n",
      " 4   has_burglar_alarm        12397 non-null  bool   \n",
      " 5   portable_electronics     12397 non-null  bool   \n",
      " 6   coast                    12397 non-null  int64  \n",
      " 7   fire_housing_proximity   12397 non-null  int64  \n",
      " 8   previous_policies        12397 non-null  int64  \n",
      " 9   user_age                 12397 non-null  float64\n",
      " 10  card_type                12396 non-null  object \n",
      " 11  label                    12397 non-null  bool   \n",
      " 12  number_of_na             12397 non-null  int64  \n",
      " 13  grouped_postal_code      12397 non-null  object \n",
      " 14  median_household_income  12396 non-null  float64\n",
      "dtypes: bool(4), float64(3), int64(4), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f'bool_cols\\n\\n {bool_cols}')\n",
    "print(f'\\n\\ncategorical_cols\\n\\n {categorical_cols}')\n",
    "print(f'\\n\\nnumerical_cols\\n\\n {numerical_cols}\\n\\n')\n",
    "df_not_encoded_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990d62d",
   "metadata": {},
   "source": [
    "###### 3.2) Define pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe629f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @staticmethod\n",
      "    def run_gridsearchCV_with_pipline(X_train: pd.DataFrame,\n",
      "                                      y_train: pd.Series,\n",
      "                                      numerical_cols: List[str],\n",
      "                                      categorical_cols: List[str],\n",
      "                                      bool_cols: List[str],\n",
      "                                      fixed_params: dict,\n",
      "                                      gs_params: dict):\n",
      "        '''\n",
      "        Run grid search with cross validation pipeline\n",
      "        :param X_train: pd.DataFrame - feature matrix\n",
      "        :param y_train: pd.Series - target vactore\n",
      "        :param numerical_cols: List[str] - numerical features\n",
      "        :param categorical_cols: List[str] - Categorical features\n",
      "        :param bool_cols: List[str] - Boolean features\n",
      "        :param fixed_params: dict - not for grid search\n",
      "        :param gs_params: dict -  for grid search\n",
      "        :return: GridSearchCV model (contain best model params)\n",
      "        '''\n",
      "        categorical_transformer = Pipeline(steps=\n",
      "                                           [('imputer', SimpleImputer(strategy='most_frequent')\n",
      "\n",
      "                                             ),\n",
      "                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
      "\n",
      "        continuous_transformer = Pipeline(steps=\n",
      "                                          [('imputer', SimpleImputer(strategy='median')),\n",
      "                                           ('scaler', StandardScaler())])\n",
      "\n",
      "        boll_transformer = Pipeline(steps=\n",
      "                                    [('imputer', SimpleImputer(strategy='most_frequent'))]\n",
      "                                    )\n",
      "\n",
      "        preprocessor = ColumnTransformer(transformers=\n",
      "                                         [('num', continuous_transformer, numerical_cols),\n",
      "                                          ('cat', categorical_transformer, categorical_cols),\n",
      "                                          ('bool', boll_transformer, bool_cols)]\n",
      "                                         )\n",
      "\n",
      "        model = GradientBoostingClassifier(**fixed_params)\n",
      "        #model = LogisticRegression(**fixed_params)\n",
      "\n",
      "        pipeline = Pipeline(steps=\n",
      "                            [('preprocess', preprocessor),\n",
      "                             ('model', model)])\n",
      "\n",
      "        grid = GridSearchCV(pipeline,\n",
      "                            param_grid=gs_params, scoring='f1', cv=3, n_jobs=4, iid=False\n",
      "                            )\n",
      "        grid = grid.fit(X_train * 1, y_train)\n",
      "        return grid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(pt.run_gridsearchCV_with_pipline)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517992a9",
   "metadata": {},
   "source": [
    "###### 3.3) Run gread search with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7df5daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pt.run_gridsearchCV_with_pipline(X_train=X_train, \n",
    "                                     y_train=y_train,\n",
    "                                     numerical_cols=numerical_cols,\n",
    "                                     categorical_cols=categorical_cols,\n",
    "                                     bool_cols=bool_cols,\n",
    "                                     fixed_params=fixed_params,\n",
    "                                     gs_params=gs_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6d139",
   "metadata": {},
   "source": [
    "###### 3.4) GridSerachCV - results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d74edd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__loss</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.344966</td>\n",
       "      <td>0.222615</td>\n",
       "      <td>0.702963</td>\n",
       "      <td>0.024634</td>\n",
       "      <td>exponential</td>\n",
       "      <td>12</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "      <td>{'model__loss': 'exponential', 'model__max_dep...</td>\n",
       "      <td>0.500317</td>\n",
       "      <td>0.890861</td>\n",
       "      <td>0.899783</td>\n",
       "      <td>0.763654</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.797974</td>\n",
       "      <td>0.405647</td>\n",
       "      <td>0.866664</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>exponential</td>\n",
       "      <td>12</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>{'model__loss': 'exponential', 'model__max_dep...</td>\n",
       "      <td>0.501586</td>\n",
       "      <td>0.891585</td>\n",
       "      <td>0.899752</td>\n",
       "      <td>0.764308</td>\n",
       "      <td>0.185802</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.006838</td>\n",
       "      <td>0.186057</td>\n",
       "      <td>0.666034</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>exponential</td>\n",
       "      <td>12</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>400</td>\n",
       "      <td>{'model__loss': 'exponential', 'model__max_dep...</td>\n",
       "      <td>0.500317</td>\n",
       "      <td>0.890861</td>\n",
       "      <td>0.899783</td>\n",
       "      <td>0.763654</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.535018</td>\n",
       "      <td>0.211123</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>exponential</td>\n",
       "      <td>12</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>{'model__loss': 'exponential', 'model__max_dep...</td>\n",
       "      <td>0.501586</td>\n",
       "      <td>0.891585</td>\n",
       "      <td>0.899752</td>\n",
       "      <td>0.764308</td>\n",
       "      <td>0.185802</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.107229</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.775710</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>exponential</td>\n",
       "      <td>12</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "      <td>{'model__loss': 'exponential', 'model__max_dep...</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>0.892480</td>\n",
       "      <td>0.897991</td>\n",
       "      <td>0.763173</td>\n",
       "      <td>0.186778</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       7.344966      0.222615         0.702963        0.024634   \n",
       "1       9.797974      0.405647         0.866664        0.085940   \n",
       "2       8.006838      0.186057         0.666034        0.035801   \n",
       "3      10.535018      0.211123         0.831514        0.032263   \n",
       "4      10.107229      0.363475         0.775710        0.061486   \n",
       "\n",
       "  param_model__loss param_model__max_depth param_model__max_features  \\\n",
       "0       exponential                     12                      sqrt   \n",
       "1       exponential                     12                      sqrt   \n",
       "2       exponential                     12                      sqrt   \n",
       "3       exponential                     12                      sqrt   \n",
       "4       exponential                     12                      sqrt   \n",
       "\n",
       "  param_model__min_samples_leaf param_model__min_samples_split  \\\n",
       "0                            20                             40   \n",
       "1                            20                             40   \n",
       "2                            20                             30   \n",
       "3                            20                             30   \n",
       "4                            10                             40   \n",
       "\n",
       "  param_model__n_estimators  \\\n",
       "0                       400   \n",
       "1                       500   \n",
       "2                       400   \n",
       "3                       500   \n",
       "4                       400   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__loss': 'exponential', 'model__max_dep...           0.500317   \n",
       "1  {'model__loss': 'exponential', 'model__max_dep...           0.501586   \n",
       "2  {'model__loss': 'exponential', 'model__max_dep...           0.500317   \n",
       "3  {'model__loss': 'exponential', 'model__max_dep...           0.501586   \n",
       "4  {'model__loss': 'exponential', 'model__max_dep...           0.499048   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.890861           0.899783         0.763654        0.186243   \n",
       "1           0.891585           0.899752         0.764308        0.185802   \n",
       "2           0.890861           0.899783         0.763654        0.186243   \n",
       "3           0.891585           0.899752         0.764308        0.185802   \n",
       "4           0.892480           0.897991         0.763173        0.186778   \n",
       "\n",
       "   rank_test_score  \n",
       "0               24  \n",
       "1               16  \n",
       "2               24  \n",
       "3               16  \n",
       "4               32  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39030b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best params ---\n",
      "\n",
      "{'model__loss': 'exponential', 'model__max_depth': 14, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 10, 'model__min_samples_split': 40, 'model__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Best params ---\\n\\n{grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd8b488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best score ---\n",
      "\n",
      "0.7693178387733149\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Best score ---\\n\\n{grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130717e",
   "metadata": {},
   "source": [
    "##### 3.3) Combine params before full training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adaaa18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final model params ---\n",
      "\n",
      "{'learning_rate': 0.1, 'max_features': 'sqrt', 'subsample': 0.8, 'random_state': 10, 'model__loss': 'exponential', 'model__max_depth': 14, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 10, 'model__min_samples_split': 40, 'model__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "fixed_params.update(grid.best_params_)\n",
    "final_model_params = fixed_params\n",
    "print(f\"--- Final model params ---\\n\\n{final_model_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe686f4",
   "metadata": {},
   "source": [
    "##### 3.4) Performence on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b20f60a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.1,\n",
       " 'confusion_matrix': array([[1784,   34],\n",
       "        [  38,    4]])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting bool to int (imputer cant dill with booleans)\n",
    "X_test = X_test*1\n",
    "\n",
    "# Predict for test set \n",
    "y_pred = grid.predict(X_test)\n",
    "pt.evaluate(y_true=y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0197bc",
   "metadata": {},
   "source": [
    "### 4) Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "130cfd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./production/grid_search_models/gread_search_2021-04-24.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.grid_search.last_model_path = f'./production/grid_search_models/gread_search_{date.today()}.pkl'\n",
    "joblib.dump(grid, configs.grid_search.last_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f611d",
   "metadata": {},
   "source": [
    "### 5) Save configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9918ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = {\"model_params\":fixed_params,\n",
    "         \"model_path\":configs.model_path,\n",
    "         \"grid_search\":{\"last_model_path\":configs.grid_search.last_model_path, \n",
    "                        \"grid_params\": { \"n_estimators\": [400,500],\n",
    "                                         \"max_depth\": [12, 14],\n",
    "                                         \"min_samples_split\": [40,30],\n",
    "                                         \"min_samples_leaf\": [20,10],\n",
    "                                         \"max_features\": [ 'sqrt'],\n",
    "                                         \"loss\": ['exponential','deviance']},\n",
    "                                        \n",
    "         \n",
    "                        \"fixed_params\":{\"learning_rate\":0.1, \n",
    "                                        \n",
    "                                        \"max_features\":'sqrt',\n",
    "                                        \"subsample\":0.8,\n",
    "                                        \"random_state\":10}},\n",
    "        \"sanity\":{\"sanity_check_path\" : './production/sanity_check/sampels.txt'}}\n",
    "\n",
    "\n",
    "with open(config_path, 'w') as outfile:\n",
    "    json.dump(confs, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5ee01",
   "metadata": {},
   "source": [
    "##### Save 5 request for sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "074043ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_train.iloc[0:5,:].to_dict(\"index\")\n",
    "with open('./production/sanity_check/sampels.txt', 'w') as outfile:\n",
    "    samples = json.dump(d,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80779d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
